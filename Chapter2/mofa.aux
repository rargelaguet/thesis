\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {0.1}Multi-Omics Factor Analysis: a framework for unsupervised integration of multi-omics data sets}{1}{section.0.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.1}Model description}{1}{subsection.0.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{Interpretation of the factors}{1}{section*.2}}
\@writefile{toc}{\contentsline {subsubsection}{Interpretation of the loadings}{2}{section*.3}}
\@writefile{toc}{\contentsline {subsubsection}{Interpretation of the noise}{2}{section*.4}}
\@writefile{toc}{\contentsline {subsubsection}{Missing values}{2}{section*.5}}
\@writefile{toc}{\contentsline {subsubsection}{Prior distributions for the factors and the loadings}{2}{section*.6}}
\newlabel{likelihood}{{7}{3}{Prior distributions for the factors and the loadings}{equation.0.1.7}{}}
\newlabel{likelihood@cref}{{[equation][7][0]7}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.2}Downstream analysis}{3}{subsection.0.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces MOFA overview. The model takes $M$ data matrices as input (${\bf  Y}^1, \cdots  , {\bf  Y}^M$), one or more from each data modality, with co-occurrent samples but features that are not necessarily related and can differ in numbers. MOFA decomposes these matrices into a matrix of factors (${\bf  Z}$) and $M$ weight matrices, one for each data modality (${\bf  W}^1, \cdots  , {\bf  W}^M$). White cells in the weight matrices correspond to zeros, i.e. inactive features, whereas the cross symbol in the data matrices denotes missing values. The fitted MOFA model can be queried for different downstream analyses, including a variance decomposition to assess the proportion of variance explained by each factor in each data modality.\relax }}{4}{figure.caption.7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:MOFA}{{1}{4}{MOFA overview. The model takes $M$ data matrices as input ($\bfY ^1, \cdots , \bfY ^M$), one or more from each data modality, with co-occurrent samples but features that are not necessarily related and can differ in numbers. MOFA decomposes these matrices into a matrix of factors ($\bfZ $) and $M$ weight matrices, one for each data modality ($\bfW ^1, \cdots , \bfW ^M$). White cells in the weight matrices correspond to zeros, i.e. inactive features, whereas the cross symbol in the data matrices denotes missing values. The fitted MOFA model can be queried for different downstream analyses, including a variance decomposition to assess the proportion of variance explained by each factor in each data modality.\relax }{figure.caption.7}{}}
\newlabel{fig:MOFA@cref}{{[figure][1][0]1}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Graphical model for MOFA. The white circles represent hidden variables that are infered by the model, whereasa the grey circles represent the observed variables. There are a total of four plates, each one representing a dimension of the model: $M$ for the number of views, $N$ for the number of samples, $K$ for the number of factors and $D_m$ for the number of features in view $m$\relax }}{5}{figure.caption.8}}
\newlabel{fig:MOFA_graphical_model}{{2}{5}{Graphical model for MOFA. The white circles represent hidden variables that are infered by the model, whereasa the grey circles represent the observed variables. There are a total of four plates, each one representing a dimension of the model: $M$ for the number of views, $N$ for the number of samples, $K$ for the number of factors and $D_m$ for the number of features in view $m$\relax }{figure.caption.8}{}}
\newlabel{fig:MOFA_graphical_model@cref}{{[figure][2][0]2}{5}}
\@writefile{toc}{\contentsline {subsubsection}{Inference}{5}{section*.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.3}Monitoring convergence}{5}{subsection.0.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Training curve for two diffent initialisations of MOFA. The y-axis displays the log of the ELBO, with higher values indicating a better fit. The x-axis displays the iteration number. The horizontal dash lines mark the value of the ELBO upon convergence. \relax }}{6}{figure.caption.10}}
\newlabel{fig:elbo_convergence}{{3}{6}{Training curve for two diffent initialisations of MOFA. The y-axis displays the log of the ELBO, with higher values indicating a better fit. The x-axis displays the iteration number. The horizontal dash lines mark the value of the ELBO upon convergence. \relax }{figure.caption.10}{}}
\newlabel{fig:elbo_convergence@cref}{{[figure][3][0]3}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.4}Model selection and consistency across random initilizations}{6}{subsection.0.1.4}}
\newlabel{section:robustness}{{0.1.4}{6}{Model selection and consistency across random initilizations}{subsection.0.1.4}{}}
\newlabel{section:robustness@cref}{{[subsection][4][0,1]0.1.4}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  Model selection and robustness analysis in MOFA. The left plot the log ELBO (y-axis) for 25 model instances (x-axis). The arrow indicates the model with the highest ELBO that would be selected for downstream analysis. The right plot displays the absolute value of the Pearson correlation coefficient between pairwise combinations of all factors across the 25 model instances. A block-diagonal matrix indicates that factors are robustly estimated regardless of the initialisation.\relax }}{6}{figure.caption.11}}
\newlabel{fig:MOFA_robustness}{{4}{6}{Model selection and robustness analysis in MOFA. The left plot the log ELBO (y-axis) for 25 model instances (x-axis). The arrow indicates the model with the highest ELBO that would be selected for downstream analysis. The right plot displays the absolute value of the Pearson correlation coefficient between pairwise combinations of all factors across the 25 model instances. A block-diagonal matrix indicates that factors are robustly estimated regardless of the initialisation.\relax }{figure.caption.11}{}}
\newlabel{fig:MOFA_robustness@cref}{{[figure][4][0]4}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.5}Learning the number of factors}{7}{subsection.0.1.5}}
\newlabel{section:number_factors}{{0.1.5}{7}{Learning the number of factors}{subsection.0.1.5}{}}
\newlabel{section:number_factors@cref}{{[subsection][5][0,1]0.1.5}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Training curve for the number of active factors across 25 different model instances. The y-axis displays the number of active factors. The x-axis displays the iteration number. Different lines denote different model instances.\relax }}{7}{figure.caption.12}}
\newlabel{fig:MOFA_nfactors}{{5}{7}{Training curve for the number of active factors across 25 different model instances. The y-axis displays the number of active factors. The x-axis displays the iteration number. Different lines denote different model instances.\relax }{figure.caption.12}{}}
\newlabel{fig:MOFA_nfactors@cref}{{[figure][5][0]5}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.6}Modelling and inference with non-Gaussian data}{7}{subsection.0.1.6}}
\newlabel{section:non_gaussian}{{0.1.6}{7}{Modelling and inference with non-Gaussian data}{subsection.0.1.6}{}}
\newlabel{section:non_gaussian@cref}{{[subsection][6][0,1]0.1.6}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.7}Model validation with simulated data}{10}{subsection.0.1.7}}
\newlabel{section:mofa_simulated}{{0.1.7}{10}{Model validation with simulated data}{subsection.0.1.7}{}}
\newlabel{section:mofa_simulated@cref}{{[subsection][7][0,1]0.1.7}{10}}
\@writefile{toc}{\contentsline {subsubsection}{Recovery of the latent space}{10}{section*.15}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Assessing the ability of MOFA to recover simulated latent spaces. In all plots the y-axis displays the number of infered factors. (a) x-axis displays the number of true factors, and boxplots summarise the distribution across 10 model instances. For (c-d) the true number of factors was set to $K=10$ and each bar corresponds to a different model instance. (b) x-axis displays the number of features, (c) x-axis displays the number of views, (d) x-axis displays fraction of missing values. \relax }}{11}{figure.caption.16}}
\newlabel{fig:MOFA_learnK}{{6}{11}{Assessing the ability of MOFA to recover simulated latent spaces. In all plots the y-axis displays the number of infered factors. (a) x-axis displays the number of true factors, and boxplots summarise the distribution across 10 model instances. For (c-d) the true number of factors was set to $K=10$ and each bar corresponds to a different model instance. (b) x-axis displays the number of features, (c) x-axis displays the number of views, (d) x-axis displays fraction of missing values. \relax }{figure.caption.16}{}}
\newlabel{fig:MOFA_learnK@cref}{{[figure][6][0]6}{11}}
\@writefile{toc}{\contentsline {subsubsection}{Group-wise sparsity on the loadings}{11}{section*.17}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Evaluating the ability of MOFA, iCluster and GFA to recover sparse factor activity patterns across views. The leftmost plot displays the true activity pattern, with factors being (strongly) active in different subsets of views. The remaining three plots show, for each model, the fraction of variance explained ($R^2$) by each factor in each view.\relax }}{12}{figure.caption.18}}
\newlabel{fig:MOFA_group_sparsity}{{7}{12}{Evaluating the ability of MOFA, iCluster and GFA to recover sparse factor activity patterns across views. The leftmost plot displays the true activity pattern, with factors being (strongly) active in different subsets of views. The remaining three plots show, for each model, the fraction of variance explained ($R^2$) by each factor in each view.\relax }{figure.caption.18}{}}
\newlabel{fig:MOFA_group_sparsity@cref}{{[figure][7][0]7}{12}}
\@writefile{toc}{\contentsline {subsubsection}{Feature-wise sparsity on the loadings}{12}{section*.19}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Assessing sparsity on the loadings in MOFA. The plot shows the empirical cumulative density function of the loadings for an arbitrary factor in a single view. The loadings were simulated with a sparsity level of $\theta _k^m=0.5$ (50\% of active features.) \relax }}{12}{figure.caption.20}}
\newlabel{fig:MOFA_sparsity}{{8}{12}{Assessing sparsity on the loadings in MOFA. The plot shows the empirical cumulative density function of the loadings for an arbitrary factor in a single view. The loadings were simulated with a sparsity level of $\theta _k^m=0.5$ (50\% of active features.) \relax }{figure.caption.20}{}}
\newlabel{fig:MOFA_sparsity@cref}{{[figure][8][0]8}{12}}
\@writefile{toc}{\contentsline {subsubsection}{Non-gaussian likelihoods}{13}{section*.21}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Validation of the non-gaussian likelihood models implemented in MOFA on simulated data. The four plots on the left assess the Poisson and the Gaussian likelihoods applied to count data. The four plots on the right assess the Bernoulli and the Gaussian likelihoods applied to binary data. (a) The y-axis displays the ELBO for each model instance (x-axis). (b) The y-axis displays the mean reconstruction error for each model instance (x-axis). (c) The y-axis displays the number of estimated factrors for each model instance (x-axis). The horizontal dashed line marks the true number of factors $K=10$. (d) Distribution of reconstructed data.\relax }}{13}{figure.caption.22}}
\newlabel{fig:MOFA_nongaussian}{{9}{13}{Validation of the non-gaussian likelihood models implemented in MOFA on simulated data. The four plots on the left assess the Poisson and the Gaussian likelihoods applied to count data. The four plots on the right assess the Bernoulli and the Gaussian likelihoods applied to binary data. (a) The y-axis displays the ELBO for each model instance (x-axis). (b) The y-axis displays the mean reconstruction error for each model instance (x-axis). (c) The y-axis displays the number of estimated factrors for each model instance (x-axis). The horizontal dashed line marks the true number of factors $K=10$. (d) Distribution of reconstructed data.\relax }{figure.caption.22}{}}
\newlabel{fig:MOFA_nongaussian@cref}{{[figure][9][0]9}{13}}
\@writefile{toc}{\contentsline {subsubsection}{Scalability}{13}{section*.23}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Evaluation of speed and scalability in MOFA. The y-axis displays the time required for convergence. The x-axis displays the value of the dimension that was tested, either number of factors ($K$), number of features ($D$), number of samples ($N$) and number of views ($M$). Baseline parameters were $M=3, K=10, D=1000, N=100$. Each line represents a different model, GFA (red), MOFA (blue) and iCluster (green). Default convergence criteria where used for all methods. Each dot displays the average time across 10 trials with error bars denoting the standard deviation. iCluster is only shown for one value as all other settings required more than 200min for convergence. \relax }}{14}{figure.caption.24}}
\newlabel{fig:MOFA_nongaussian}{{10}{14}{Evaluation of speed and scalability in MOFA. The y-axis displays the time required for convergence. The x-axis displays the value of the dimension that was tested, either number of factors ($K$), number of features ($D$), number of samples ($N$) and number of views ($M$). Baseline parameters were $M=3, K=10, D=1000, N=100$. Each line represents a different model, GFA (red), MOFA (blue) and iCluster (green). Default convergence criteria where used for all methods. Each dot displays the average time across 10 trials with error bars denoting the standard deviation. iCluster is only shown for one value as all other settings required more than 200min for convergence. \relax }{figure.caption.24}{}}
\newlabel{fig:MOFA_nongaussian@cref}{{[figure][10][0]10}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.8}Application to chronic lymphocytic leukaemia}{14}{subsection.0.1.8}}
\newlabel{section:mofa_cll}{{0.1.8}{14}{Application to chronic lymphocytic leukaemia}{subsection.0.1.8}{}}
\newlabel{section:mofa_cll@cref}{{[subsection][8][0,1]0.1.8}{14}}
\@writefile{toc}{\contentsline {subsubsection}{Model overview}{15}{section*.25}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces XX\relax }}{16}{figure.caption.26}}
\newlabel{fig:MOFA_CLL_Figure1}{{11}{16}{XX\relax }{figure.caption.26}{}}
\newlabel{fig:MOFA_CLL_Figure1@cref}{{[figure][11][0]11}{16}}
\@writefile{toc}{\contentsline {subsubsection}{Characterisation of Factor 1}{16}{section*.27}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces XX\relax }}{17}{figure.caption.28}}
\newlabel{fig:MOFA_IGHV_outlier}{{12}{17}{XX\relax }{figure.caption.28}{}}
\newlabel{fig:MOFA_IGHV_outlier@cref}{{[figure][12][0]12}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces XX\relax }}{18}{figure.caption.29}}
\newlabel{fig:MOFA_CLL_Factor1}{{13}{18}{XX\relax }{figure.caption.29}{}}
\newlabel{fig:MOFA_CLL_Factor1@cref}{{[figure][13][0]13}{18}}
\@writefile{toc}{\contentsline {subsubsection}{Characterisation of other Factors}{18}{section*.30}}
\@writefile{toc}{\contentsline {subsubsection}{Prediction of clinical outcome}{18}{section*.31}}
\@writefile{toc}{\contentsline {subsubsection}{Imputation of missing values}{18}{section*.32}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Evaluation of imputation performance in the drug response assay of the CLL data. The y-axis shows averages of the mean-squared error across 15 trials for increasing fractions of missing data (x-axis). Two experiments were considered: (a) values missing at random and (b) entire assays missing at random. Error bars represent standard deviations.\relax }}{19}{figure.caption.33}}
\newlabel{fig:MOFA_imputation}{{14}{19}{Evaluation of imputation performance in the drug response assay of the CLL data. The y-axis shows averages of the mean-squared error across 15 trials for increasing fractions of missing data (x-axis). Two experiments were considered: (a) values missing at random and (b) entire assays missing at random. Error bars represent standard deviations.\relax }{figure.caption.33}{}}
\newlabel{fig:MOFA_imputation@cref}{{[figure][14][0]14}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.9}Application to single-cell multi-omics}{19}{subsection.0.1.9}}
\newlabel{section:mofa_scmt}{{0.1.9}{19}{Application to single-cell multi-omics}{subsection.0.1.9}{}}
\newlabel{section:mofa_scmt@cref}{{[subsection][9][0,1]0.1.9}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces XX\relax }}{21}{figure.caption.34}}
\newlabel{fig:MOFA_scMT}{{15}{21}{XX\relax }{figure.caption.34}{}}
\newlabel{fig:MOFA_scMT@cref}{{[figure][15][0]15}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces XX\relax }}{22}{figure.caption.35}}
\newlabel{fig:MOFA_scMT2}{{16}{22}{XX\relax }{figure.caption.35}{}}
\newlabel{fig:MOFA_scMT2@cref}{{[figure][16][0]16}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces XX\relax }}{22}{figure.caption.36}}
\newlabel{fig:MOFA_scMT_clustering}{{17}{22}{XX\relax }{figure.caption.36}{}}
\newlabel{fig:MOFA_scMT_clustering@cref}{{[figure][17][0]17}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.10}Open perspectives}{23}{subsection.0.1.10}}
\@setckpt{Chapter2/mofa}{
\setcounter{page}{25}
\setcounter{equation}{7}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{0}
\setcounter{section}{1}
\setcounter{subsection}{10}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{17}
\setcounter{table}{0}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{parentequation}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{11}
\setcounter{float@type}{16}
\setcounter{algorithm}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{2}
\setcounter{maxnames}{3}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextrayear}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{lstnumber}{1}
\setcounter{section@level}{2}
\setcounter{lstlisting}{0}
}
