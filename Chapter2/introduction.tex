\graphicspath{{Chapter2/Figs/}}

\chapter{Multi-Omics Factor Analysis (MOFA), a Bayesian model for integration of multi-omics data}

The work described in this chapter results from a collaboration with Wolfgang Huber's group at the EMBL (Heidelberg, Germany). It has been peer-reviewed and published in \cite{Argelaguet2018}.\\
The method was conceived by Florian Buettner, Oliver Stegle and me. I performed most of the mathematical derivations and implementation, but with significant contributions from Damien Arnol and Britta Velten. The CLL data application was led by Britta Velten whereas the single-cell application was led by me, but with joint contributions in either cases. Florian Buettner, Wolfgang Huber and Oliver Stegle supervised the project.\\
The article was jointly written by Britta Velten and me, with contributions from all authors.

\section{Theoretical foundations}

\subsection{Mathematical notation} \label{section:mathematical_notation}

\begin{itemize}[noitemsep]
	\item[--] Matrices are denoted with bold capital letters: $\bfW$
	\item[--] Vectors are denoted with bold non-capital letters: $\bfw$. If the vector comes from a matrix, we will use a single index to indicate the row that it comes from. If two indices are used, the first one corresponds to the row and the second one to the column. The symbol '$:$' denotes the entire row/column. For instance, $\bfw_{i}$ refers to the $i$th row from the $\bfW$ matrix, whereas $\bfw_{:,j}$ refers to the $j$th column.
	\item[--] Scalars are denoted with non-bold and non-capital letters: $w$. If the scalar comes from a 1-dimensional array (a vector), a single subscript will indicate its position in the vector. If the scalar comes from a 2-dimensional array, two indices will be shown at the bottom: the first one corresponding to the row and the second one to the column. For instance, $w_{i,j}$ refers to the value from the $i$th row and the $j$th column of the matrix $\bfW$, and $w_i$ to the $i$th value of the vector $\bfw$. In some cases, higher dimensional arrays (tensors) are used, and the use of multiple indices follows the same rationale.
	\item[--] $\boldzero_k$ is a zero vector of length $k$.
	\item[--] $\I_k$ is the identity matrix with rank $k$.
	\item[--] $\E_q[x]$ denotes the expectation of $x$ under the distribution $q$. When the expectations are taken with respect to the same distribution many times, we will avoid cluttered notation and we will instead use $\la x \ra$.
	\item[--] $\Ndist{x}{\mu,\sigma^2}$: $x$ follows a univariate normal distribution with mean $\mu$ and variance $\sigma^2$.
	\item[--] $\Gdist{x}{a,b}$: $x$ follows a gamma distribution with shape and rate parameters $a$ and $b$.
	\item[--] $\Bdist{x}{a, b}$: $x$ follows a beta distribution with shape and rate parameters $a$ and $b$.
	\item[--] $\text{Ber}(x|\theta)$: $x$ follows a Bernoulli distribution with parameter $\theta$.
	\item[--] $\mathds{1}_0$: Dirac delta function centered at 0.
	\item[--] $Tr(\bfX)$: Trace of the matrix \bfX
\end{itemize}

\subsection{Graphical notation for probabilistic models}

Probabilistic models can be represented in a diagrammatic format (i.e. a graph or a network) that offers a compact visual representation of complicated systems of probability distributions \cite{Bishop2006}. In a graphical model the relationship between the nodes becomes more explicit, namely their conditional independence properties which allow the joint distribution over all variables to be factorised into a series of simpler products involving subsets of variables \cite{Bishop2006}. The basic unit of a network is the node, which represents the different types of variables, including observed variables, unobserved probabilistic variables and unobserved parameters. The nodes are connected by unidirectional edges (arrows) which capture the conditional independence relationship between the variables.

For this thesis we adapted the graphical notations from~\cite{Dietz2010-technical-report-graphs}:

\begin{center}
  \begin{tabular}{m{8cm} m{2cm}}
    Observed variables & \tikz{\node[obs](){$Y$}} \\
    Unobserved probabilistic variables & \tikz{\node[latent](){$\theta$}} \\
    Unobserved parameters & \tikz{\node[latent,double, double distance=1pt](){$\theta$}} \\
    Repetition of node $\theta_n$ for $n\in\llbracket 1;N \rrbracket$ & \tikz{\node[latent](theta){$\theta_n$}; \plate[] {plateN} {(theta)} {$N$};} \\
    Conditional dependency between nodes: $p(Y,\theta) = p(Y|\theta)p(\theta)$ & \tikz{%
            \node[latent]   (theta) {$\theta$};
            \node[obs, xshift=1.5cm] (Y) {$Y$};
            \edge{theta}{Y}}
  \end{tabular}
\end{center}
% For simplicity, fixed hyperparameters are not represented on the graphical model. Unobserved parameters are only represented when optimised together with the unobserved probabilistic variables.



\input{Chapter2/bayes}

\input{Chapter2/factor_analysis}