@ARTICLE{Minka2001,
       author = {{Minka}, Thomas P.},
        title = "{Expectation Propagation for approximate Bayesian inference}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
         year = "2013",
        month = "Jan",
          eid = {arXiv:1301.2294},
        pages = {arXiv:1301.2294},
archivePrefix = {arXiv},
       eprint = {1301.2294}

}



@article{Cao2019,
	Abstract = {Mammalian organogenesis is a remarkable process. Within a short timeframe, the cells of the three germ layers transform into an embryo that includes most of the major internal and external organs. Here we investigate the transcriptional dynamics of mouse organogenesis at single-cell resolution. Using single-cell combinatorial indexing, we profiled the transcriptomes of around 2 million cells derived from 61 embryos staged between 9.5 and 13.5 days of gestation, in a single experiment. The resulting `mouse organogenesis cell atlas'(MOCA) provides a global view of developmental processes during this critical window. We use Monocle 3 to identify hundreds of cell types and 56 trajectories, many of which are detected only because of the depth of cellular coverage, and collectively define thousands of corresponding marker genes. We explore the dynamics of gene expression within cell types and trajectories over time, including focused analyses of the apical ectodermal ridge, limb mesenchyme and skeletal muscle.},
	Author = {Cao, Junyue and Spielmann, Malte and Qiu, Xiaojie and Huang, Xingfan and Ibrahim, Daniel M. and Hill, Andrew J. and Zhang, Fan and Mundlos, Stefan and Christiansen, Lena and Steemers, Frank J. and Trapnell, Cole and Shendure, Jay},
	Doi = {10.1038/s41586-019-0969-x},
	Id = {Cao2019},
	Isbn = {1476-4687},
	Journal = {Nature},
	Number = {7745},
	Pages = {496--502},
	Title = {The single-cell transcriptional landscape of mammalian organogenesis},
	Volume = {566},
	Year = {2019}
}



@ARTICLE{Martens2014,
	author = {{Martens}, James},
	title = "{New insights and perspectives on the natural gradient method}",
	journal = {arXiv e-prints},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	year = "2014",
	month = "Dec",
	eid = {arXiv:1412.1193},
	pages = {arXiv:1412.1193},
	archivePrefix = {arXiv},
	eprint = {1412.1193},
	primaryClass = {cs.LG}
}


@misc{Kristiadi2019,
	author = {Kristiadi, Agustinus},
	title = {Natural Gradient Descent},
	type = {Blog},
	number = {January 23},
	year = {2019},
	howpublished = {\url{https://wiseodd.github.io/techblog/2018/03/14/natural-gradient/}}
}
@incollection{Platt2008,
	title = {Fast Variational Inference for Large-scale Internet Diagnosis},
	author = {Emre Kiciman and David Maltz and John C. Platt},
	booktitle = {Advances in Neural Information Processing Systems 20},
	editor = {J. C. Platt and D. Koller and Y. Singer and S. T. Roweis},
	pages = {1169--1176},
	year = {2008},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.nips.cc/paper/3292-fast-variational-inference-for-large-scale-internet-diagnosis.pdf}
}


@article{Ranganath2014,
	author = {{Ranganath}, Rajesh and {Gerrish}, Sean and {Blei}, David M.},
	title = "{Black Box Variational Inference}",
	journal = {arXiv e-prints},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Statistics - Computation, Statistics - Methodology},
	year = 2013,
	month = Dec,
	eid = {arXiv:1401.0118},
	pages = {arXiv:1401.0118},
	archivePrefix = {arXiv},
	eprint = {1401.0118},
	primaryClass = {stat.ML}
}



@book{Spall2003,
	title     = "Introduction to stochastic search and optimization: estimation, simulation, and control",
	author    = "Spall, James C",
	publisher = "J. Wiley",
	year      =  2003,
	address   = "Hoboken, N.J"
}


@book{Murphy,
	author = {Murphy, Kevin P.},
	title = {Machine Learning: A Probabilistic Perspective},
	year = {2012},
	isbn = {0262018020, 9780262018029},
	publisher = {The MIT Press},
}


@inproceedings{Ranganath2013,
	author = {Ranganath, Rajesh and Wang, Chong and Blei, David M. and Xing, Eric P.},
	title = {An Adaptive Learning Rate for Stochastic Variational Inference},
	booktitle = {Proceedings of the 30th International Conference on International Conference on Machine Learning - Volume 28},
	series = {ICML'13},
	year = {2013},
	pages = {II-298--II-306},
	url = {http://dl.acm.org/citation.cfm?id=3042817.3042927},
	publisher = {JMLR.org},
}

@article{Saul1996,
	author = {{Saul}, L.~K. and {Jaakkola}, T. and {Jordan}, M.~I.},
	title = "{Mean Field Theory for Sigmoid Belief Networks}",
	journal = {arXiv e-prints},
	keywords = {Computer Science - Artificial Intelligence},
	year = 1996,
	month = Feb,
	eid = {cs/9603102},
	pages = {cs/9603102},
	archivePrefix = {arXiv},
	eprint = {cs/9603102}
}


@article{Zhao2009,
	title = "A note on variational Bayesian factor analysis",
	journal = "Neural Networks",
	volume = "22",
	number = "7",
	pages = "988 - 997",
	year = "2009",
	issn = "0893-6080",
	doi = "https://doi.org/10.1016/j.neunet.2008.11.002",
	url = "http://www.sciencedirect.com/science/article/pii/S0893608008002670",
	author = "Jian-hua Zhao and Philip L.H. Yu"
}


@article{Svensson2018,
	Author = {Svensson, Valentine and Vento-Tormo, Roser and Teichmann, Sarah A},
	Date = {2018/03/01/online},
	Day = {01},
	Journal = {Nature Protocols},
	Month = {03},
	Pages = {599 EP  -},
	Publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved. SN  -},
	Title = {Exponential scaling of single-cell RNA-seq in the past decade},
	Url = {https://doi.org/10.1038/nprot.2017.149},
	Volume = {13},
	Year = {2018}
}


@incollection{Mackay1996,
	title={Bayesian methods for backpropagation networks},
	author={MacKay, David JC},
	booktitle={Models of neural networks III},
	pages={211--254},
	year={1996},
	publisher={Springer}
}


@article{Mitchell1988,
	title={Bayesian variable selection in linear regression},
	author={Mitchell, Toby J and Beauchamp, John J},
	journal={Journal of the American Statistical Association},
	volume={83},
	number={404},
	pages={1023--1032},
	year={1988},
	publisher={Taylor \& Francis}
}


@article{Gao2013,
	author = {{Gao}, Chuan and {Brown}, Christopher D and {Engelhardt}, Barbara E},
	title = "{A latent factor model with a mixture of sparse and dense factors to model gene expression data with confounding effects}",
	journal = {arXiv e-prints},
	keywords = {Statistics - Applications, Quantitative Biology - Genomics},
	year = 2013,
	eid = {arXiv:1310.4792},
	pages = {arXiv:1310.4792},
	archivePrefix = {arXiv},
	eprint = {1310.4792},
	primaryClass = {stat.AP},
	adsurl = {https://ui.adsabs.harvard.edu/\#abs/2013arXiv1310.4792G},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}




@article{Argelaguet2018,
	author = {Argelaguet, R. and Velten, B. and Arnol, D. and Dietrich, S. and Zenz, T. and Marioni, J. C. and Buettner, F. and Huber, W. and Stegle, O.},
	title = {Multi-Omics Factor Analysis-a framework for unsupervised integration of multi-omics data sets},
	journal = {Mol Syst Biol},
	volume = {14},
	number = {6},
	pages = {e8124},
	ISSN = {1744-4292 (Electronic) 1744-4292 (Linking)},
	DOI = {10.15252/msb.20178124},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/29925568},
	year = {2018},
	type = {Journal Article}
}


@thesis{Beal2003,
	author       = {JM Beal},
	title        = {Variational algorithms for approximate bayesian inference},
	school       = {University College London},
	year         = {2003}
}


@article{Jordan1999,
  title    = "An Introduction to Variational Methods for Graphical Models",
  author   = "Jordan, Michael I and Ghahramani, Zoubin and Jaakkola, Tommi S
              and Saul, Lawrence K",
  journal  = "Mach. Learn.",
  volume   =  37,
  number   =  2,
  pages    = "183--233",
  month    =  nov,
  year     =  1999
}


@article{Amari1998,
  title     = "Natural Gradient Works Efficiently in Learning",
  author    = "Amari, Shun-Ichi",
  journal   = "Neural Comput.",
  publisher = "MIT Press",
  volume    =  10,
  number    =  2,
  pages     = "251--276",
  month     =  feb,
  year      =  1998
}


@article{Robbins-Monro1951,
	title     = "A stochastic approximation method",
	author    = "Robbins, H. and Monro, S.",
	journal   = "The Annals of Mathematical Statistics",
	volume    =  22,
	number    =  3,
	pages     = "400â€“407",
	year      =  1951
}


@article{Emtiyaz2018,
	author = {{Emtiyaz Khan}, Mohammad and {Nielsen}, Didrik},
	title = "{Fast yet Simple Natural-Gradient Descent for Variational Inference in Complex Models}",
	journal = {arXiv e-prints},
	year = 2018,
	month = Jul,
	eid = {arXiv:1807.04489},
	pages = {arXiv:1807.04489},
	archivePrefix = {arXiv},
	eprint = {1807.04489},
	primaryClass = {stat.ML}
}



@article{Hoffman2012,
	author = {{Hoffman}, Matt and {Blei}, David M. and {Wang}, Chong and {Paisley}, John},
	title = "{Stochastic Variational Inference}",
	journal = {arXiv e-prints},
	year = 2012,
	month = Jun,
	eid = {arXiv:1206.7051},
	pages = {arXiv:1206.7051},
	eprint = {1206.7051}
}


@inproceedings{Seeger2012,
	title={Fast variational Bayesian inference for non-conjugate matrix factorization models},
	author={Seeger, Matthias and Bouchard, Guillaume},
	booktitle={Artificial Intelligence and Statistics},
	pages={1012--1018},
	year={2012}
}


@article{Jaakkola2000,
	title={Bayesian parameter estimation via variational methods},
	author={Jaakkola, Tommi S and Jordan, Michael I},
	journal={Statistics and Computing},
	volume={10},
	number={1},
	pages={25--37},
	year={2000},
	publisher={Springer}
}


@inproceedings{Titsias2011,
	title={Spike and slab variational inference for multi-task and multiple kernel learning},
	author={Titsias, Michalis K and L{\'a}zaro-Gredilla, Miguel},
	booktitle={Advances in neural information processing systems},
	pages={2339--2347},
	year={2011}
}


@article{Bishop,
	title={Pattern recognition},
	author={Bishop, Christopher M},
	journal={Machine Learning},
	volume={128},
	pages={1--58},
	year={2006}
}


@article{bunte2016sparse,
	title={Sparse group factor analysis for biclustering of multiple data sources},
	author={Bunte, Kerstin and Lepp{\"a}aho, Eemeli and Saarinen, Inka and Kaski, Samuel},
	journal={Bioinformatics},
	volume={32},
	number={16},
	pages={2457--2463},
	year={2016},
	publisher={Oxford Univ Press}
}



@inproceedings{cupy2017,
	author       = "Okuta, Ryosuke and Unno, Yuya and Nishino, Daisuke and Hido, Shohei and Loomis, Crissman",
	title        = "CuPy: A NumPy-Compatible Library for NVIDIA GPU Calculations",
	booktitle    = "Proceedings of Workshop on Machine Learning Systems (LearningSys) in The Thirty-first Annual Conference on Neural Information Processing Systems (NIPS)",
	year         = "2017",
	url          = "http://learningsys.org/nips17/assets/papers/paper_16.pdf"
}


@article{Zhang2017,
	author = {{Zhang}, Cheng and {Butepage}, Judith and {Kjellstrom}, Hedvig and
	{Mandt}, Stephan},
	title = "{Advances in Variational Inference}",
	journal = {arXiv e-prints},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	year = 2017,
	month = Nov,
	eid = {arXiv:1711.05597},
	pages = {arXiv:1711.05597},
	archivePrefix = {arXiv},
	eprint = {1711.05597}
}


@article{Hoffman2014,
	author = {{Hoffman}, Matthew D. and {Blei}, David M.},
	title = "{Structured Stochastic Variational Inference}",
	journal = {arXiv e-prints},
	keywords = {Computer Science - Machine Learning},
	year = 2014,
	month = Apr,
	eid = {arXiv:1404.4114},
	pages = {arXiv:1404.4114},
	archivePrefix = {arXiv},
	eprint = {1404.4114}
}


@article{Blei2016,
	author = {{Blei}, David M. and {Kucukelbir}, Alp and {McAuliffe}, Jon D.},
	title = "{Variational Inference: A Review for Statisticians}",
	journal = {arXiv e-prints},
	keywords = {Statistics - Computation, Computer Science - Machine Learning, Statistics - Machine Learning},
	year = 2016,
	month = Jan,
	eid = {arXiv:1601.00670},
	pages = {arXiv:1601.00670},
	archivePrefix = {arXiv},
	eprint = {1601.00670},
	primaryClass = {stat.CO}
}

@PHDTHESIS{Hore2015-thesis,
  title  = "Latent Variable Models for Analysing Multidimensional Gene Expression Data",
  author = "Hore, Victoria",
  year   =  2015,
  school = "University of Oxford"
}


@ARTICLE{Stigler2008,
       author = {{Stigler}, Stephen M.},
        title = "{The Epic Story of Maximum Likelihood}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Methodology},
         year = "2008",
        month = "Apr",
          eid = {arXiv:0804.2996},
        pages = {arXiv:0804.2996},
archivePrefix = {arXiv},
       eprint = {0804.2996},
 primaryClass = {stat.ME},
       adsurl = {https://ui.adsabs.harvard.edu/\#abs/2008arXiv0804.2996S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



@book{Hastie,
 author = {Hastie, Trevor and Tibshirani, Robert and Wainwright, Martin},
 title = {Statistical Learning with Sparsity: The Lasso and Generalizations},
 year = {2015},
 isbn = {1498712169, 9781498712163},
 publisher = {Chapman \& Hall/CRC},
} 

@article{Bayes1763,
author = {Thomas Bayes  and null Price },
title = {LII. An essay towards solving a problem in the doctrine of chances. By the late Rev. Mr. Bayes, F. R. S. communicated by Mr. Price, in a letter to John Canton, A. M. F. R. S},
journal = {Philosophical Transactions of the Royal Society of London},
volume = {53},
number = {},
pages = {370-418},
year = {1763},
doi = {10.1098/rstl.1763.0053},
URL = {https://royalsocietypublishing.org/doi/abs/10.1098/rstl.1763.0053},
eprint = {https://royalsocietypublishing.org/doi/pdf/10.1098/rstl.1763.0053}
}





% @book{Raiffa1961,
%   title={Applied statistical decision theory},
%   author={Ra{\"\i}ffa, H. and Schlaifer, R.},
%   isbn={9780875840178},
%   lccn={60011282},
%   series={Studies in managerial economics},
%   url={https://books.google.co.uk/books?id=wPBLAAAAMAAJ},
%   year={1961},
%   publisher={Division of Research, Graduate School of Business Adminitration, Harvard University}
% }


@misc{Gelman2013,
    author = {Gelman, Andrew and Carlin, John and Stern, Hal and Dunson, David and Vehtari, Aki and Rubin, Donald},
    day = {01},
    edition = {Third},
    howpublished = {Hardcover},
    isbn = {1439840954},
    keywords = {bayes},
    month = nov,
    publisher = {Chapman and Hall/CRC},
    title = {Bayesian Data Analysis, Third Edition (Chapman \& {Hall/CRC} Texts in Statistical Science)},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/1439840954},
    year = {2013}
}




@article{Jaynes1968,
	Author = {E.  T.  Jaynes},
	Journal = {IEEE Transactions on Systems Science and Cybernetics},
	Number = {3},
	Pages = {227--241},
	Title = {Prior Probabilities},
	Volume = {4},
	Year = {1968}}



@article{Craiu2014,
	Author = {Craiu, Radu V. and Rosenthal, Jeffrey S.},
	Journal = {Annual Review of Statistics and Its Application},
	Month = {2019/03/14},
	Number = {1},
	Pages = {179--201},
	Title = {Bayesian Computation Via Markov Chain Monte Carlo},
	Volume = {1},
	Year = {2014}}



@article{Rue2009,
 ISSN = {13697412, 14679868},
 URL = {http://www.jstor.org/stable/40247579},
 abstract = {Structured additive regression models are perhaps the most commonly used class of models in statistical applications. It includes, among others, (generalized) linear models, (generalized) additive models, smoothing spline models, state space models, semiparametric regression, spatial and spatiotemporal models, log-Gaussian Cox processes and geostatistical and geoadditive models. We consider approximate Bayesian inference in a popular subset of structured additive regression models, latent Gaussian models, where the latent field is Gaussian, controlled by a few hyperparameters and with non-Gaussian response variables. The posterior marginals are not available in closed form owing to the non-Gaussian response variables. For such models, Markov chain Monte Carlo methods can be implemented, but they are not without problems, in terms of both convergence and computational time. In some practical applications, the extent of these problems is such that Markov chain Monte Carlo sampling is simply not an appropriate tool for routine analysis. We show that, by using an integrated nested Laplace approximation and its simplified version, we can directly compute very accurate approximations to the posterior marginals. The main benefit of these approximations is computational: where Markov chain Monte Carlo algorithms need hours or days to run, our approximations provide more precise estimates in seconds or minutes. Another advantage with our approach is its generality, which makes it possible to perform Bayesian analysis in an automatic, streamlined way, and to compute model comparison criteria and various predictive measures so that models can be compared and the model under study can be challenged.},
 author = {HÃ¥vard Rue and Sara Martino and Nicolas Chopin},
 journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
 number = {2},
 pages = {319--392},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Approximate Bayesian Inference for Latent Gaussian Models by Using Integrated Nested Laplace Approximations},
 volume = {71},
 year = {2009}
}

